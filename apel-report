#!/usr/bin/env python
"""
Report generator for APEL.

Author: Henrik Thostrup Jensen <htj@ndgf.org>
Copyright: Nordic Data Grid Facility (2009)

This script is essentially a big back of hacks to form and merge accounting
data into something that can go into APEL.


Usage examples:

./apel-report

Use whatever is defined in config.json and generate report for the current year+month

./apel-report -y 2010 -m 01

Generate report for january 2010

./apel-report -c otherconfig.json

Use otherconfig.json as config file.

./apel-report -t

Generate tier report.

"""

import sys
import json
import time
import logging
import calendar
import subprocess
from optparse import OptionParser

import psycopg2


DEFAULT_CONFIG_FILE = 'config.json'
DEFAULT_LOG_FILE = '/var/log/apel-reporter.log'

DAY_OVERLAP = 3  # day into a month for doing report for previous month

NDGF_TIER1   = 'NDGF-T1'
NORWAY_TIER2 = 'NO-NORGRID-T2'
SWEDEN_TIER2 = 'SE-SNIC-T2'
CSC_TIER     = 'CSC' # this is apparently what it is called

ALIEN_USER_PREFIX = '/C=ch/O=AliEn/OU=ALICE/'

# constants for accessing values in records
TIER      = 'tier'
HOST      = 'host'
USERSN    = 'usersn'
VO_NAME   = 'vo_name'
VO_ISSUER = 'vo_issuer'
VO_GROUP  = 'vo_group'
VO_ROLE   = 'vo_role'
N_JOBS    = 'n_jobs'
CPU_DURATION        = 'cpu_duration'
WALL_DURATION       = 'wall_duration'
KSI2K_CPU_DURATION  = 'ksi2k_cpu_duration'
KSI2K_WALL_DURATION = 'ksi2k_wall_duration'
YEAR       = 'year'
MONTH      = 'month'
DATE_START = 'date_start'
DATE_END   = 'date_end'

# a global to avoid us spamming missing scale factors
FACTOR_HOST_WARNINGS = {}


ENTRY_COMPARE = lambda r1, r2: cmp(
    (r1.get(TIER), r1.get(VO_NAME), r1.get(USERSN)),
    (r2.get(TIER), r2.get(VO_NAME), r2.get(USERSN))
)


def createParser():

    gmt = time.gmtime()
    d_year  = gmt.tm_year
    d_month = gmt.tm_mon

    parser = OptionParser()
    parser.add_option('-i', '--interactive', dest='interactive',
                      help='Run in interactive mode (no registrations are performed', default=False, action='store_true')
    parser.add_option('-t', '--tier',   dest='tierreport', help='Generate tier report', default=False, action='store_true')
    parser.add_option('-c', '--config', dest='config',     help='Configuration file', metavar='FILE', default=DEFAULT_CONFIG_FILE )
    parser.add_option('-l', '--logfile',dest='logfile',    help='Log file', metavar='FILE', default=DEFAULT_LOG_FILE)
    parser.add_option('-y', '--year',   dest='year',       help='Report generation year',  default=d_year, type=int)
    parser.add_option('-m', '--month',  dest='month',      help='Report generation month', default=d_month, type=int)

    return parser



def loadConfig(filename=DEFAULT_CONFIG_FILE):

    f = open(filename)
    try:
        cfg = json.load(f)
    except ValueError, e:
        logging.error("Error parsing configuration file (%s)", str(e))
        sys.exit(2)

    f.close()
    return cfg



def nMonthDays(year, month):

    if calendar.isleap(int(year)) and month == '02':
        return 29
    else:
        return calendar.mdays[int(month)]



def previousMonth(year, month):

    if month == 1:
        return year-1, 12
    else:
        return year, month-1



def fetchViewData(db_host, db_name, db_username, db_password, year, month):

    query = """SELECT extract(YEAR FROM execution_time) AS year, extract(MONTH FROM execution_time) AS month,
                    machine_name AS host, user_identity AS usersn, vo_issuer, vo_name, vo_group, vo_role,
                    n_jobs, cputime AS cpu_duration, walltime AS wall_duration
             FROM uraggregated
             WHERE extract(YEAR FROM execution_time) = %s AND extract(MONTH FROM execution_time) = %s"""
    query_args = (year, month)

    conn = psycopg2.connect(host=db_host, database=db_name, user=db_username, password=db_password)

    cur = conn.cursor()
    cur.execute(query, query_args)
    rows = cur.fetchall()

    conn.close()

    return rows


def rowsToDicts(rows):

    dicts = []
    for row in rows:
        year, month, host, usersn, vo_issuer, vo_name, vo_group, vo_role, n_jobs, cpu_duration, wall_duration = row

        d = { YEAR : year, MONTH : month, HOST : host, USERSN : usersn,
              VO_NAME : vo_name, VO_ISSUER : vo_issuer, VO_GROUP : vo_group, VO_ROLE : vo_role,
              N_JOBS : n_jobs, CPU_DURATION : float(cpu_duration), WALL_DURATION : float(wall_duration)
            }

        dicts.append(d)

    return dicts



def cleanData(records):
    """
    Does some cleanup of the data in order to make it more "mergeable".
    """
    def cleanRecord(record):
        # the monalisa ur logger reports jobs with alice.cern.ch vo name
        # the logger should be fixed now, but we keep it anyway
        if record[VO_NAME] == 'alice.cern.ch':
            record[VO_NAME] = 'alice'
        # remove information that is useless anyway
        if record[VO_ISSUER] and record[VO_ISSUER].startswith('file:///'):
            record[VO_ISSUER] = None
        if record[VO_NAME] and (record[VO_NAME].startswith('file:///') or record[VO_NAME].startswith('/')):
            record[VO_NAME] = None
        if record[USERSN].startswith(ALIEN_USER_PREFIX):
            record[VO_NAME] = 'alice'
            record[USERSN]  = '/aliprod'
        if record[USERSN] =='aliprod':
            record[USERSN]  = '/aliprod'

        # some users have atlas.cern.ch vo, which is not directly wrong but not right either
        # these are mostly non-andrej users so we put them in user if they have no role
        # these are actually non-voms users, but which comes with a reverse vo mapping
        # this is all heuristics
        if record[VO_NAME] == 'atlas.cern.ch' and record[VO_ISSUER].startswith('vomss://voms.cern.ch:8443/voms/atlas'):
            record[VO_NAME] = 'atlas'
            if record[USERSN] == '/C=SI/O=SiGNET/O=IJS/OU=F9/CN=Andrej Filipcic':
                record[VO_GROUP] = 'atlas'
                record[VO_ROLE] = 'production'

        # hack for missing vo info on Andrej - turn them into production jobs which is probably 99% right
        if record[USERSN] == '/C=SI/O=SiGNET/O=IJS/OU=F9/CN=Andrej Filipcic' and \
           record[VO_ISSUER] == None and \
           record[VO_NAME] == None:
            record[VO_ISSUER] = '/DC=ch/DC=cern/OU=computers/CN=voms.cern.ch'
            record[VO_NAME]   = 'atlas'
            record[VO_GROUP]  = 'atlas'
            record[VO_ROLE]   = 'production'

        return record

    return [ cleanRecord(r) for r in records ]



def filterData(records):
    """
    Filters out "uninteresting" data.
    """
    def isInteresting(record):
        if record[VO_ISSUER] in ('/DC=ch/DC=cern/OU=computers/CN=voms.cern.ch', '/DC=ch/DC=cern/OU=computers/CN=lcg-voms.cern.ch'):
            return True
        if record[VO_NAME] in ('atlas', 'cms', 'alice'):
            return True
        if record[USERSN] == '/C=SI/O=SiGNET/O=IJS/OU=F9/CN=Andrej Filipcic':
            return True
        if record[USERSN] in ('aliprod', '/aliprod'):
            return True
        if record[USERSN].startswith(ALIEN_USER_PREFIX):
            return True

        return False

    return [ r for r in records if isInteresting(r) ]



def mergeRecords(recs):
    """
    Merge two or more records, keeping their base information, but adding count variables.
    Assumes base information is identical.
    """
    def sumfield(dicts, field):
        fields = [ d[field] for d in dicts ]
        result = sum(fields) if not None in fields else None
        return result

    nr = recs[0].copy()
    nr[N_JOBS]              = sumfield(recs, N_JOBS)
    nr[CPU_DURATION]        = sumfield(recs, CPU_DURATION)
    nr[KSI2K_CPU_DURATION]  = sumfield(recs, KSI2K_CPU_DURATION)
    nr[WALL_DURATION]       = sumfield(recs, WALL_DURATION)
    nr[KSI2K_WALL_DURATION] = sumfield(recs, KSI2K_WALL_DURATION)

    return nr



def mergeSimilarRecords(records, tier_report=False):
    """
    Merge records if the host and user information is similar.
    """

    idx = {}

    for r in records:
        if tier_report:
            key = (r[HOST], r[VO_NAME], r[VO_ROLE])
            r.pop(USERSN, None) ; r.pop(VO_GROUP, None)
        else:
            key = (r[HOST], r[USERSN], r[VO_NAME], r[VO_GROUP], r[VO_ROLE])
        idx.setdefault(key, []).append(r)

    merged_records = []
    for key, recs in idx.items():
        if len(recs) == 1:
            mr = recs[0]
        else:
            # debug output
            mr = mergeRecords(recs)
            # this is fairly complex, so we keep the debugging print logic
            if False:
                print "MERGING:"
                for r in recs:
                    for k in sorted(r): print k, ":", r[k], ", ",
                    print
                print "-->"
                for k in sorted(mr): print k, ":", mr[k], ", ",
                print
                print "----------------------"
                print

        # vo issuer is removed in merging, as it is often the reason for merging
        mr[VO_ISSUER] = None
        merged_records.append(mr)

    return merged_records



def addFactors(records, factors, factor_host_warnings=FACTOR_HOST_WARNINGS):
    """
    Add factors for ksi2k scaling for cern reference.
    """
    # note: the magic factor for converting ksi2k factors to
    # hs06 factors is to multiply with 4, i.e., ksi2k*4 = hs06

    UNKNOWN_FACTOR = 1.75

    for r in records:
        if r[HOST] in factors:
            r[KSI2K_CPU_DURATION] = r[CPU_DURATION] * factors[r[HOST]]
            r[KSI2K_WALL_DURATION] = r[WALL_DURATION] * factors[r[HOST]]
        else:
            if not r[HOST] in factor_host_warnings:
                logging.warning("No scale factor for host %s, using %s", r[HOST], round(UNKNOWN_FACTOR,2))
                factor_host_warnings[r[HOST]] = True
            r[KSI2K_CPU_DURATION] = r[CPU_DURATION] * UNKNOWN_FACTOR
            r[KSI2K_WALL_DURATION] =  r[WALL_DURATION] * UNKNOWN_FACTOR

    return records



def mergeToTiers(records, tier_mapping, tier_shares, tier_report=False):

    DEFAULT_TIER = NDGF_TIER1

    def mapHostToTier(host):
        try:
            return tier_mapping[host]
        except KeyError:
            logging.warning("No tier mapping for host %s", host)
        # using heuristic
        if host.endswith('.no'):
            tier = NORWAY_TIER2
        elif host.endswith('.se'):
            tier = SWEDEN_TIER2
        elif host.endswith('.fi'):
            tier = CSC_TIER
        else:
            tier = DEFAULT_TIER
        return tier


    def ruleMatch(rule, record):
        for key, value in rule.items():
            try:
                if record[key] != value:
                    return False
            except KeyError:
                return False
        return True


    def applyRatio(record, ratio):
        nr = {}
        nr[N_JOBS] = int(record[N_JOBS] * ratio)
        nr[CPU_DURATION]  = record[CPU_DURATION]  * ratio
        nr[WALL_DURATION] = record[WALL_DURATION] * ratio
        nr[KSI2K_CPU_DURATION]  = record[KSI2K_CPU_DURATION]  * ratio if record[KSI2K_CPU_DURATION]  else None
        nr[KSI2K_WALL_DURATION] = record[KSI2K_WALL_DURATION] * ratio if record[KSI2K_WALL_DURATION] else None
        return nr


    # start of function

    # key: tier, usersn, vo_name, vo_group, vo_role / tier, vo_name
    tr = {}

    for r in records:

        host = r[HOST]
        tier = mapHostToTier(host)

        rc = r.copy()
        #print rc[HOST], rc[USERSN], rc[VO_NAME], rc[VO_GROUP], rc[VO_ROLE]
        rc[TIER] = tier
        del rc[HOST]

        match = False
        for rule, ratio in tier_shares:
            if ruleMatch(rule, rc):
                match = True
                break

        # apply fucked splitting of entries - just for atlas though
        #if rc[VO_NAME] in ('atlas', 'cms'):
        if tier_report:
            if rc[VO_NAME] == 'atlas':
                if rc[VO_ROLE] == 'production':
                    rc[VO_NAME] = rc[VO_NAME] + '-prod'
                else:
                    rc[VO_NAME] = rc[VO_NAME] + '-user'
            rc.pop(VO_ROLE, None)

        # we don't split entries if there are less than 10 jobs,
        # as it creates small meaningless entries, which are just noise
        # also, if ratio is 0 or 1 skip the check as it is meaningless
        if match and not rc[N_JOBS] > 10 and ratio not in (0,1):
            #print >> sys.stderr, "SPLIT AVOIDANCE:", rc.get(TIER), rc.get(VO_NAME), rc.get(USERSN), rc.get(VO_GROUP), rc.get(VO_ROLE), rc.get(N_JOBS)
            pass

        if match and rc[N_JOBS] > 10:
            #print "SPLIT", rc[TIER], rc[USERSN], rc[VO_NAME], rc[VO_GROUP], rc[VO_ROLE], rc[N_JOBS]
            t2_ratio = ratio
            t1_ratio = 1 - t2_ratio

            if tier_report:
                base_record = {VO_NAME : rc[VO_NAME] }
            else:
                base_record = {USERSN  : rc[USERSN],  VO_ISSUER : rc[VO_ISSUER],
                               VO_NAME : rc[VO_NAME], VO_GROUP  : rc[VO_GROUP],  VO_ROLE : rc[VO_ROLE]}

            if t1_ratio != 0:
                if tier_report:
                    t1_key = (NDGF_TIER1, rc[VO_NAME])
                else:
                    t1_key = (NDGF_TIER1, rc[USERSN], rc[VO_NAME], rc[VO_GROUP], rc[VO_ROLE])
                t1r = applyRatio(rc, t1_ratio)
                t1r[TIER] = t1_key[0]
                t1r.update(base_record)

                mrs = [ t1r, tr[t1_key] ] if t1_key in tr else [ t1r ]
                tr[t1_key] = mergeRecords(mrs)

            if t2_ratio != 0:
                if tier_report:
                    t2_key = (rc[TIER], rc[VO_NAME])
                else:
                    t2_key = (rc[TIER], rc[USERSN], rc[VO_NAME], rc[VO_GROUP], rc[VO_ROLE])
                t2r = applyRatio(rc, t2_ratio)
                t2r[TIER] = t2_key[0]
                t2r.update(base_record)

                mrs = [ t2r, tr[t2_key] ] if t2_key in tr else [ t2r ]
                tr[t2_key] = mergeRecords(mrs)

        else:
            # add the values to the tier which the entry was mapped to earlier - this might be correct - maybe not
            if tier_report:
                r_key = (rc[TIER], rc[VO_NAME])
            else:
                r_key = (rc[TIER], rc[USERSN], rc[VO_NAME], rc[VO_GROUP], rc[VO_ROLE])
            mrs = [ rc, tr[r_key] ] if r_key in tr else [ rc ]
            tr[r_key] = mergeRecords(mrs)

    return tr.values()



def encryptUserSN(usersn):

    cmd = './apel-crypt'
    args = [cmd, usersn]

    p = subprocess.Popen(args, stdout=subprocess.PIPE)
    p.wait()
    encrypted_usersn = p.stdout.read().strip()

    return encrypted_usersn



def encryptEntries(entries):
    """
    Encrypts the usersn in entries, as required by APEL.
    """
    logging.info('Encrypting %i entries.', len(entries))

    encrypted_entries = []

    for entry in entries:
        ec = entry.copy()
        ec['usersn'] = encryptUserSN(entry['usersn'])
        encrypted_entries.append(ec)
        sys.stdout.write('.')
        sys.stdout.flush()
    sys.stdout.write('\n')
    sys.stdout.flush()

    return encrypted_entries



def formatRecord(record, year, month, date_start, date_end, tier_report=False):
    """
    Given a record and auxillary information, this function returns a string
    containing a row suitable for insertion into APEL.
    """

    addQuotes = lambda s : "'" + s + "'"

    rd = {}

    rd[HOST]                = addQuotes(record[HOST])      if HOST in record    else addQuotes(record[TIER])
    rd[VO_NAME]             = addQuotes(record[VO_NAME])   if record[VO_NAME]   else 'null'
    if not tier_report:
        rd[USERSN]              = addQuotes(record[USERSN])
        rd[VO_ISSUER]           = addQuotes(record[VO_ISSUER]) if record[VO_ISSUER] else "''"
        rd[VO_GROUP]            = addQuotes(record[VO_GROUP])  if record[VO_GROUP]  else "''"
        rd[VO_ROLE]             = addQuotes(record[VO_ROLE])   if record[VO_ROLE]   else "''"
    rd[N_JOBS]              = record[N_JOBS]
    rd[CPU_DURATION]        = int(record[CPU_DURATION])
    rd[WALL_DURATION]       = int(record[WALL_DURATION])
    rd[KSI2K_CPU_DURATION]  = int(record[KSI2K_CPU_DURATION]) if record[KSI2K_CPU_DURATION]  is not None else 'null'
    rd[KSI2K_WALL_DURATION] = int(record[KSI2K_WALL_DURATION]) if record[KSI2K_WALL_DURATION] is not None else 'null'
    rd[MONTH]               = month
    rd[YEAR]                = year
    rd[DATE_START]          = addQuotes(date_start)
    rd[DATE_END]            = addQuotes(date_end)

    # proper db entry, full
    if tier_report:
        base = '''%(host)s, %(vo_name)s, ''' + \
               '''%(n_jobs)i, %(cpu_duration)s, %(ksi2k_cpu_duration)s, %(wall_duration)s, %(ksi2k_wall_duration)s, ''' + \
               '''%(month)s, %(year)s, %(date_start)s, %(date_end)s'''
    else:
        base = '''%(host)s, %(vo_name)s, %(usersn)s, %(vo_group)s, %(vo_role)s, ''' + \
               '''%(n_jobs)i, %(cpu_duration)s, %(ksi2k_cpu_duration)s, %(wall_duration)s, %(ksi2k_wall_duration)s, ''' + \
               '''%(month)s, %(year)s, %(date_start)s, %(date_end)s'''

    s = base % rd
    return s



def retrieveMonthlyRecords(db_host, db_name, db_username, db_password, year, month, factors):

    logging.info("Fetching data from view. Year: %i, Month %i", year, month)
    rows = fetchViewData(db_host, db_name, db_username, db_password, year, month)
    logging.info("Got view data, performing hacky data manipulation")
    records = rowsToDicts(rows)
    records = cleanData(records)
    records = filterData(records)
    records = addFactors(records, factors)
    return records


def createReport(records, tier_report=True, tier_mapping=None, tier_share=None, encrypt=None):

    if encrypt is None:
        encrypt = tier_report

    records = mergeSimilarRecords(records, tier_report=tier_report)
    entries = mergeToTiers(records, tier_mapping, tier_share, tier_report=tier_report)
    if encrypt:
        entries = encryptEntries(entries)

    return entries



def createDatabaseStatements(db_records, year, month, tier_report=True):
    # only works for tier_repors so far

    TIER_INSERT_TEMPLATE = 'INSERT INTO SGAS_DATA VALUES (%s);'
    TIER_DELETE_TEMPLATE = 'DELETE FROM SGAS_DATA WHERE year = %i AND month = %i;'

    USER_INSERT_TEMPLATE = 'INSERT INTO SGAS_DATA_USER VALUES (%s);'
    USER_DELETE_TEMPLATE = 'DELETE FROM SGAS_DATA_USER WHERE year = %i AND month = %i;' 

    stmts = []
    if tier_report:
        stmts.append(TIER_DELETE_TEMPLATE % (year, month))
        for dbr in db_records:
            stmts.append(TIER_INSERT_TEMPLATE % dbr)
    else:
        stmts.append(USER_DELETE_TEMPLATE % (year, month))
        for dbr in db_records:
            stmts.append(USER_INSERT_TEMPLATE % dbr)
    return stmts



def doDatabaseInsertion(statements):

    import MySQLdb as mysql
    logging.info('Issuing update to APEL database')

    connection = None
    try:
        connection = mysql.connect(read_default_file='~/.my.cnf-apel')
        cursor = connection.cursor()
        for stm in statements:
            cursor.execute(stm)
        cursor.close()
        connection.commit()
        logging.info('Database successfully updated. Executed %i statements', len(statements))

    except mysql.Error, e:
        logging.error("MySQL Error: %s", str(e))
        #logging.exception(e)
        if connection is not None:
            connection.rollback()

    finally:
        if connection is not None:
            connection.close()



def main():

    parser = createParser()
    options, args = parser.parse_args()

    if args:
        print "Auxillary arguments (%s) not understood, exiting." % ','.join(args)
        sys.exit(1)

    if options.interactive:
        logging.basicConfig(format='%(message)s', level=logging.INFO)
    else:
        logging.basicConfig(filename=options.logfile,
                            format='%(asctime)s %(levelname)s %(message)s',
                            level=logging.INFO)
        logging.info('== APEL Reporter invoked ==')

    cfg = loadConfig(options.config)
    factors, tier_mapping, tier_share = cfg['factor'], cfg['tier-2'], cfg['share']

    db_host = cfg.get('db-host', 'localhost')
    db_name = cfg.get('db-name', 'sgas')
    db_username = cfg.get('db-username')
    db_password = cfg.get('db-password')

    if db_username is None or db_password is None:
        logging.error("Database login (username and/or password) is not specified in config file.")
        sys.exit(1)

    tier_report = options.tierreport
    year  = options.year
    month = options.month

    if not options.interactive:
        if year < 2010 or year > 2013:
            logging.error('Time appear to have warped at the machine. Cowardly bailing out.')
            sys.exit(4)

    encrypt = not tier_report and not options.interactive

    # options ready, start data fetching

    current_time = time.gmtime()

    report_prev_month = (not options.interactive) and current_time.tm_mday <= DAY_OVERLAP

    if report_prev_month:
        logging.info('First generating report for previous month')
        prev_year, prev_month = previousMonth(year, month)
        prev_month_records = retrieveMonthlyRecords(db_host, db_name, db_username, db_password, prev_year, prev_month, factors)
        prev_entries = createReport(prev_month_records, tier_report, tier_mapping, tier_share, encrypt)
        prev_date_start = '%s-%s-%s' % (prev_year, prev_month, '1')
        prev_date_end   = '%s-%s-%s' % (prev_year, prev_month, nMonthDays(prev_year, prev_month))
        prev_db_records = [ formatRecord(e, prev_year, prev_month, prev_date_start, prev_date_end, tier_report=tier_report)
                            for e in sorted(prev_entries, ENTRY_COMPARE) ]

    month_records = retrieveMonthlyRecords(db_host, db_name, db_username, db_password, year, month, factors)
    entries = createReport(month_records, tier_report, tier_mapping, tier_share, encrypt)

    date_start = '%s-%s-%s' % (year, month, '1')
    date_end   = '%s-%s-%s' % (year, month, current_time.tm_mday)

    db_records = [ formatRecord(e, year, month, date_start, date_end, tier_report=tier_report) for e in sorted(entries, ENTRY_COMPARE) ]
    if options.interactive:
        for r in db_records:
            print r

    # ---

    else:
        statements = []
        if report_prev_month:
            statements += createDatabaseStatements(prev_db_records, prev_year, prev_month, tier_report=tier_report);
        statements += createDatabaseStatements(db_records, year, month, tier_report=tier_report)
        # this should probably be changed, log is quite difficult to read
        logging.debug('Will issue the following %i statements')
        for s in statements:
            logging.debug(s)
        doDatabaseInsertion(statements)

    if not options.interactive:
        logging.info('== APEL Reporter finished ==')


if __name__ == '__main__':
    main()

